{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification in Machine learning\n",
    "\n",
    "\n",
    "Written by: M.Danish Azeem\\\n",
    "Date: 01.18.2024\\\n",
    "Email: danishazeem365@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assighnment #1\n",
    "# Time stamp   04:35\n",
    " \n",
    "# whey we convert categorical variables into integers in machine learning preprosesing\n",
    "\n",
    "**Here are the main reasons why we convert categorical variables into integers during machine learning preprocessing:**\n",
    "\n",
    "**1. Algorithm Compatibility:**\n",
    "  - Most machine learning algorithms are designed to work with numerical data. They use mathematical calculations and distance-based metrics that rely on numbers.\n",
    "  - Categorical variables, which represent distinct groups or categories (e.g., \"male\" and \"female\"), cannot be directly processed by these algorithms.\n",
    "  - Converting them into integers allows algorithms to handle them effectively.\n",
    "\n",
    "**2. Meaningful Representation:**\n",
    "  - Integer encoding assigns a unique numerical value to each category, creating a meaningful representation that algorithms can interpret.\n",
    "  - It preserves the distinctions between categories while making them suitable for numerical computations.\n",
    "\n",
    "**3. Feature Importance:**\n",
    "  - Integer encoding enables algorithms to assess the relative importance of different categories in predicting the target variable.\n",
    "  - This can help identify which categories are more influential in the model's decision-making process.\n",
    "\n",
    "**4. Model Performance:**\n",
    "  - Appropriate encoding of categorical variables often leads to better model performance and accuracy.\n",
    "  - It ensures that algorithms can properly capture the relationships between these variables and the target variable.\n",
    "\n",
    "**5. Feature Engineering:**\n",
    "  - Integer encoding can facilitate feature engineering techniques like:\n",
    "    - Creating interaction features between categorical variables\n",
    "    - Using dimensionality reduction techniques like PCA\n",
    "\n",
    "**6. Standardization:**\n",
    "  - It contributes to data standardization, as all features become numerical, making model training and evaluation more consistent.\n",
    "\n",
    "**Common Encoding Techniques:**\n",
    "\n",
    "- **One-Hot Encoding:** Creates binary dummy variables for each category, indicating presence or absence.\n",
    "- **Ordinal Encoding:** Assigns integers based on a meaningful order or ranking within the categories.\n",
    "- **Label Encoding:** Assigns arbitrary integers to categories without any explicit order.\n",
    "\n",
    "**The choice of encoding technique depends on the specific algorithm, type of categorical variable, and domain knowledge.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assighnment #2\n",
    "# Time stamp   04:35\n",
    " \n",
    "# By using the decision tree train  model by using titanic data set and calculating 3 matrics precision Schore, recall and f1 schore\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
