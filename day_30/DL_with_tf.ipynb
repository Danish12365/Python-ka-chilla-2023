{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with computer vision in TensorFLow 2.0\n",
    "\n",
    "Written by: M.Danish Azeem\\\n",
    "Date: 02.09.2024\\\n",
    "Email: danishazeem365@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment #(1)   \n",
    "Time stamp   7:05 \n",
    "\n",
    "# what is MNIST and its abbreviation?\n",
    "\n",
    "MNIST stands for Modified National Institute of Standards and Technology (NIST) database. It's a widely used and popular benchmark dataset for training and evaluating image classification algorithms, particularly in the field of machine learning.\n",
    "MNIST plays a crucial role in the field of machine learning as a valuable tool for teaching, learning, and developing image classification algorithms. It offers a good starting point for anyone interested in exploring this area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment #(2)   \n",
    "Time stamp   11:50 \n",
    "\n",
    "# what is MNIST and read it and learn about it.\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "Why we made Fashion-MNIST\n",
    "The original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. \"If it doesn't work on MNIST, it won't work at all\", they said. \"Well, if it does work on MNIST, it may still fail on others.\"\n",
    "\n",
    "To Serious Machine Learning Researchers\n",
    "Seriously, we are talking about replacing MNIST. Here are some good reasons:\n",
    "\n",
    "MNIST is too easy. Convolutional nets can achieve 99.7% on MNIST. Classic machine learning algorithms can also achieve 97% easily. Check out our side-by-side benchmark for Fashion-MNIST vs. MNIST, and read \"Most pairs of MNIST digits can be distinguished pretty well by just one pixel.\"\n",
    "MNIST is overused. In this April 2017 Twitter thread, Google Brain research scientist and deep learning expert Ian Goodfellow calls for people to move away from MNIST.\n",
    "MNIST can not represent modern CV tasks, as noted in this April 2017 Twitter thread, deep learning expert/Keras author François Chollet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment #(3)   \n",
    "Time stamp   19:14\n",
    "\n",
    "# Read and enlist the tools to remove biasness\n",
    "\n",
    "## Tools for Removing Bias:\n",
    "\n",
    "**Data-Centric:**\n",
    "\n",
    "* **Data Collection & Filtering:**\n",
    "    * Identify & mitigate sources of bias in collection & sampling.\n",
    "    * Data cleansing, pre-processing, outlier handling.\n",
    "    * Data augmentation for diversity.\n",
    "* **Feature Engineering:**\n",
    "    * Select non-biased features.\n",
    "    * Feature transformation techniques like PCA.\n",
    "* **Fairness Metrics:**\n",
    "    * Statistical parity, equalized odds, calibration fairness.\n",
    "    * Analyze metrics to identify bias areas.\n",
    "\n",
    "**Algorithm-Centric:**\n",
    "\n",
    "* **Regularization Techniques:**\n",
    "    * L1 & L2 regularization.\n",
    "    * Fairness-aware regularization.\n",
    "* **Adversarial Debiasing:**\n",
    "    * Generate adversarial examples.\n",
    "    * Fairness-aware training loops.\n",
    "* **Counterfactual Explanations:**\n",
    "    * Explainable AI (XAI) techniques like LIME & SHAP.\n",
    "    * Counterfactual analysis.\n",
    "* **Monitoring & Testing:**\n",
    "    * Continuous monitoring of model performance & fairness metrics.\n",
    "    * A/B testing of different model versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment #(4)   \n",
    "Time stamp   21:30\n",
    "# what is 128 in this code :\n",
    "\n",
    "```python\n",
    "keras.layers.Flatten(input_shape=(28, 28)),\n",
    "keras.layers.Dense(128, activation='relu'),\n",
    "keras.layers.Dense(10, activation=\"tf.nn.softmax\")\n",
    "```\n",
    "- **`keras.layers.Dense(128, activation='relu')`:** This line defines the second layer, which is a `Dense` layer with 128 units and the ReLU activation function. These 128 units represent the number of neurons in this layer, and each neuron learns a set of weights and biases to make predictions based on the input data. The ReLU activation adds non-linearity to the layer, allowing it to learn more complex relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion MNIST dataset\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test split of the Fashion MNIST dataset\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
